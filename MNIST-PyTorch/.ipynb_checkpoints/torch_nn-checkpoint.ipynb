{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MNIST on a vanilla Feedforward NN using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.l1 = nn.Linear(28*28, 256)\n",
    "        self.l2 = nn.Linear(256, 64)\n",
    "        self.lo = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.softmax(self.lo(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (l1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (lo): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flatten:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        flattened = x.view(self.size)\n",
    "        return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_func = transforms.Compose([transforms.ToTensor(), flatten(784)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.mnist.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = dataset(root='./data', train=True, download=True, transform=trans_func)\n",
    "testdata = dataset(root='./data', train=False, download=True, transform=trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(traindata, shuffle=True, batch_size=128)\n",
    "testloader = torch.utils.data.DataLoader(testdata, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr_, momentum=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1. idx:0. Loss: 2.3025214672088623\n",
      "Epoch:1. idx:100. Loss: 2.2672176361083984\n",
      "Epoch:1. idx:200. Loss: 1.8878673315048218\n",
      "Epoch:1. idx:300. Loss: 1.6922639608383179\n",
      "Epoch:1. idx:400. Loss: 1.6322304010391235\n",
      "Epoch:2. idx:0. Loss: 1.6018824577331543\n",
      "Epoch:2. idx:100. Loss: 1.6078972816467285\n",
      "Epoch:2. idx:200. Loss: 1.6434779167175293\n",
      "Epoch:2. idx:300. Loss: 1.6004382371902466\n",
      "Epoch:2. idx:400. Loss: 1.6082031726837158\n",
      "Epoch:3. idx:0. Loss: 1.5440254211425781\n",
      "Epoch:3. idx:100. Loss: 1.5227000713348389\n",
      "Epoch:3. idx:200. Loss: 1.57520592212677\n",
      "Epoch:3. idx:300. Loss: 1.5588634014129639\n",
      "Epoch:3. idx:400. Loss: 1.5768158435821533\n",
      "Epoch:4. idx:0. Loss: 1.5310235023498535\n",
      "Epoch:4. idx:100. Loss: 1.5197468996047974\n",
      "Epoch:4. idx:200. Loss: 1.5268651247024536\n",
      "Epoch:4. idx:300. Loss: 1.521525263786316\n",
      "Epoch:4. idx:400. Loss: 1.4969745874404907\n",
      "Epoch:5. idx:0. Loss: 1.5312050580978394\n",
      "Epoch:5. idx:100. Loss: 1.5276157855987549\n",
      "Epoch:5. idx:200. Loss: 1.5090924501419067\n",
      "Epoch:5. idx:300. Loss: 1.5495930910110474\n",
      "Epoch:5. idx:400. Loss: 1.5593793392181396\n",
      "Epoch:6. idx:0. Loss: 1.549871563911438\n",
      "Epoch:6. idx:100. Loss: 1.52800452709198\n",
      "Epoch:6. idx:200. Loss: 1.5068775415420532\n",
      "Epoch:6. idx:300. Loss: 1.491389513015747\n",
      "Epoch:6. idx:400. Loss: 1.5124982595443726\n",
      "Epoch:7. idx:0. Loss: 1.4979475736618042\n",
      "Epoch:7. idx:100. Loss: 1.5210942029953003\n",
      "Epoch:7. idx:200. Loss: 1.5373188257217407\n",
      "Epoch:7. idx:300. Loss: 1.507146954536438\n",
      "Epoch:7. idx:400. Loss: 1.5085322856903076\n",
      "Epoch:8. idx:0. Loss: 1.5372430086135864\n",
      "Epoch:8. idx:100. Loss: 1.5167180299758911\n",
      "Epoch:8. idx:200. Loss: 1.5319684743881226\n",
      "Epoch:8. idx:300. Loss: 1.5022766590118408\n",
      "Epoch:8. idx:400. Loss: 1.5325894355773926\n",
      "Epoch:9. idx:0. Loss: 1.4854481220245361\n",
      "Epoch:9. idx:100. Loss: 1.5270118713378906\n",
      "Epoch:9. idx:200. Loss: 1.5408809185028076\n",
      "Epoch:9. idx:300. Loss: 1.5094234943389893\n",
      "Epoch:9. idx:400. Loss: 1.5235596895217896\n",
      "Epoch:10. idx:0. Loss: 1.4978983402252197\n",
      "Epoch:10. idx:100. Loss: 1.5156182050704956\n",
      "Epoch:10. idx:200. Loss: 1.5152795314788818\n",
      "Epoch:10. idx:300. Loss: 1.5114179849624634\n",
      "Epoch:10. idx:400. Loss: 1.514319658279419\n",
      "Epoch:11. idx:0. Loss: 1.497541069984436\n",
      "Epoch:11. idx:100. Loss: 1.522358775138855\n",
      "Epoch:11. idx:200. Loss: 1.5407942533493042\n",
      "Epoch:11. idx:300. Loss: 1.5163841247558594\n",
      "Epoch:11. idx:400. Loss: 1.5021306276321411\n",
      "Epoch:12. idx:0. Loss: 1.5429186820983887\n",
      "Epoch:12. idx:100. Loss: 1.5134066343307495\n",
      "Epoch:12. idx:200. Loss: 1.507538080215454\n",
      "Epoch:12. idx:300. Loss: 1.5208550691604614\n",
      "Epoch:12. idx:400. Loss: 1.511292815208435\n",
      "Epoch:13. idx:0. Loss: 1.5054442882537842\n",
      "Epoch:13. idx:100. Loss: 1.5301800966262817\n",
      "Epoch:13. idx:200. Loss: 1.4992315769195557\n",
      "Epoch:13. idx:300. Loss: 1.5251504182815552\n",
      "Epoch:13. idx:400. Loss: 1.5112197399139404\n",
      "Epoch:14. idx:0. Loss: 1.4993069171905518\n",
      "Epoch:14. idx:100. Loss: 1.5132009983062744\n",
      "Epoch:14. idx:200. Loss: 1.5046145915985107\n",
      "Epoch:14. idx:300. Loss: 1.5223177671432495\n",
      "Epoch:14. idx:400. Loss: 1.5169597864151\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 15):\n",
    "    for idx, data in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) #Computing loss\n",
    "        loss.backward() #Backpropagation\n",
    "        optimizer.step() #Weights update step\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print(f'Epoch:{epoch}. idx:{idx}. Loss: {loss.item()}')\n",
    "    if epoch %3 == 0:\n",
    "        lr_ /= 5\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr_, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 94.63%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for idx, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "    predicted = model(inputs)\n",
    "    predicted_prob, predicted_label = torch.max(predicted, 1)\n",
    "    correct += (predicted_label == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "print(f'Test Accuracy of the model: {100*correct/total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
