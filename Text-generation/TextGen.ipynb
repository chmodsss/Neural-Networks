{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import spacy as spc\n",
    "import pandas as pd\n",
    "import string\n",
    "import collections\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional, Dropout, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adadelta, Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "from keras.utils import multi_gpu_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('/any/previous/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puncts = string.punctuation.replace('.','')\n",
    "punct = str.maketrans('','', puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open('story.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(xx):\n",
    "    return ' '.join(x for x in xx.split() if not x.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdata = clean(data.translate(punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = [s for s in cdata.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted(collections.Counter(sents))\n",
    "vocab2idx = {v:idx for idx,v in enumerate(vocab)}\n",
    "idx2vocab = {idx:v for idx,v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "seq_step = 1\n",
    "sequences = []\n",
    "nextword = []\n",
    "for idx in range(len(sents) - seq_len):\n",
    "    seq_sent = sents[idx : idx + seq_len]\n",
    "    nxt_word = sents[idx + seq_len]\n",
    "    sequences.append(seq_sent)\n",
    "    nextword.append(nxt_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = pd.DataFrame({'sequence':sequences, 'target':nextword})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_arr = np.zeros((len(seq), seq_len, len(vocab)), dtype=bool)\n",
    "target_arr = np.zeros((len(seq), len(vocab)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s_idx,x,y in seq.itertuples(index=True):\n",
    "    target_arr[s_idx][vocab2idx[y]] = 1\n",
    "    for w_idx,word in enumerate(x):\n",
    "        sequence_arr[s_idx][w_idx][vocab2idx[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, activation='relu'), input_shape=(seq_len, len(vocab))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(vocab)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "parallel_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.5, min_lr=0.01)\n",
    "batch_size = 1024\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot2word(arr):\n",
    "    return idx2vocab[arr.argmax()]\n",
    "\n",
    "def word2onehot(word):\n",
    "    vidx = vocab2idx[word]\n",
    "    varr = np.zeros((1, len(vocab)), dtype=bool)\n",
    "    varr[0, vidx] = 1\n",
    "    return varr\n",
    "\n",
    "def prob2onehot(prob):\n",
    "    foo = np.zeros((1, len(vocab)), dtype=bool)\n",
    "    foo[0, prob.argmax()] = 1\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def headstart():\n",
    "    hswords = []\n",
    "    for w in 'Hobbits lived in the woods happily and the story begins'.split():\n",
    "        hswords.append(word2onehot(w))\n",
    "    return np.array(hswords).transpose(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_text(model, word_limit):\n",
    "    textcum = []\n",
    "    text_generated = []\n",
    "    sequence_arr = headstart()\n",
    "    text_generated.extend([x for y in sequence_arr for x in y])\n",
    "    for idx in range(word_limit):\n",
    "        predicted_arr = prob2onehot(model.predict(sequence_arr))\n",
    "        text_generated.append(predicted_arr)\n",
    "        sequence_arr = np.concatenate((sequence_arr[0, 1:, :], predicted_arr)).reshape(sequence_arr.shape)\n",
    "    for w in text_generated:\n",
    "        textcum.append(onehot2word(w))\n",
    "    return ' '.join(textcum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text(parallel_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(num_epochs):\n",
    "    parallel_model.fit(sequence_arr, target_arr, batch_size=batch_size, epochs=1, callbacks=[lr_reducer], validation_split=0.10)\n",
    "    print(gen_text(parallel_model, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/path/mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
